## 1.3 Arquitectura de Hadoop

Cuando se habla de Hadoop se hace referencia a un paquete muy amplio de software a veces tambiÃ©n denominado ecosistema Hadoop. Este paquete incluye, junto a los componentes centrales (Core Hadoop), una gran diversidad de extensiones que no solo destacan por sus curiosos nombres (Pig, Chukwa, Oozie o ZooKeeper) sino por ampliar el framework con un gran nÃºmero de funciones adicionales que sirven para la manipulaciÃ³n de extensos grupos de datos. Todos estos proyectos, estrechamente vinculados entre sÃ­, tambiÃ©n son desarrollados bajo el techo de la fundaciÃ³n Apache Software.

El fundamento del ecosistema Hadoop lo constituye el Core Hadoop. Sus componentes en la primera versiÃ³n son el mÃ³dulo bÃ¡sico Hadoop Common, el Hadoop Distributed File System (HDFS) y un motor MapReduce. A partir de la versiÃ³n 2.3 este Ãºltimo fue sustituido por la tecnologÃ­a de gestiÃ³n de clÃºsters YARN, tambiÃ©n denominada MapReduce 2.0. Esta tÃ©cnica excluye el algoritmo MapReduce del sistema de gestiÃ³n en sÃ­, de forma que a partir de este momento se convierte en un plugin basado en YARN.

Hadoop Common
El mÃ³dulo Hadoop Common pone a disposiciÃ³n de todos los demÃ¡s elementos del framework un set de funciones bÃ¡sicas, entre las cuales se encuentran los archivos .jar de Java necesarios para iniciar Hadoop, las bibliotecas para la serializaciÃ³n de datos asÃ­ como las interfaces para el acceso al sistema de archivos de la arquitectura Hadoop y la llamada a procedimiento remoto (remote procedure call o RPC) para la comunicaciÃ³n entre clientes dentro de un clÃºster. AdemÃ¡s, el mÃ³dulo tambiÃ©n contiene el cÃ³digo fuente, la documentaciÃ³n del proyecto e informaciÃ³n sobre otros proyectos de la comunidad Hadoop.

Hadoop Distributed File System (HDFS)
El sistema de archivos distribuido de Hadoop consiste en un sistema de ficheros de alta disponibilidad para el almacenamiento de un gran volumen de datos en un clÃºster de ordenadores, encargado del mantenimiento de los datos dentro del framework. Para ello, los archivos se fragmentan en bloques de datos y se distribuyen replicados en varios nodos sin seguir ningÃºn esquema. SegÃºn los propios desarrolladores, HDFS es capaz de gestionar cantidades de datos en la escala de los petabytes. Es posible configurar individualmente tanto la longitud de los bloques de datos como el grado de la redundancia.

El clÃºster de Hadoop funciona bÃ¡sicamente segÃºn el principio maestro-esclavo, de tal forma que la arquitectura del framework de software consta de un nodo maestro al cual se subordinan una variedad de nodos esclavos. Este principio tambiÃ©n se ve reflejado en la construcciÃ³n del HDFS, consistente en un namenode (nodo de nombres) y varios datanodes (nodos de datos) subordinados. El nodo de nombres administra todos los metadatos del sistema de archivos, la estructura de ficheros y los archivos. El almacenamiento en sÃ­ de los datos se produce en los nodos de datos. Para minimizar la pÃ©rdida de datos, los archivos se fragmentan en bloques y se depositan replicados en diferentes nodos. De forma predeterminada, se realizan tres copias de cada bloque.

Cada datanode envÃ­a un signo vital al namenode en periodos regulares, el llamado heartbeat (latido). Si no se produce esta seÃ±al, el namenode declara a este esclavo como â€œmuertoâ€ y se ocupa, con ayuda de las copias disponibles en otros nodos, de que, a pesar de esta caÃ­da, existan en el clÃºster suficientes copias del bloque en cuestiÃ³n. El namenode tiene, por esto, una funciÃ³n principal dentro del framework. Para que este no se convierta en el Ãºnico responsable o â€œsingle point of failureâ€, es habitual nombrarle un â€œasistenteâ€, el secondary name node, que registra todos los cambios en relaciÃ³n con los metadatos y permite de esta manera una recuperaciÃ³n de la entidad de control central.

El HDFS ampliÃ³ en el paso de Hadoop 1 a Hadoop 2 con sistemas de seguridad adicionales: namenode HA (High Availability, alta disponibilidad) completa el sistema con una protecciÃ³n automÃ¡tica ante caÃ­das, gracias a la cual se inicia un componente de sustituciÃ³n en el caso de una caÃ­da del namenode. AdemÃ¡s, la funciÃ³n Snapshot permite restablecer un estado anterior del sistema. La extensiÃ³n Federation permite ejecutar varios namenodes dentro de un clÃºster.

MapReduce Engine
Otro componente fundamental del Core Hadoop es el algoritmo MapReduce desarrollado por Google, que en la primera versiÃ³n de Hadoop aÃºn estaba implementado como motor autÃ³nomo. La tarea central de esta mÃ¡quina es la gestiÃ³n de los recursos asÃ­ como el control y el seguimiento de los procesos de cÃ¡lculo (job scheduling/monitoring). El procesamiento de los datos se basa esencialmente en las fases â€œMapâ€ y â€œReduceâ€ y se realiza directamente en el lugar donde se depositan (data locality). Esto acelera el tiempo de cÃ¡lculo y reduce el trÃ¡fico en la red.

En la fase Map los procesos de cÃ¡lculo se dividen en porciones que se denominan jobs (tareas) y que un jobtracker (rastreador de trabajos) en el nodo maestro distribuye en varios sistemas-esclavo dentro del clÃºster. Los denominados tasktracker (rastreadores de tareas) se encargan de que estas tareas o procesos trabajen en paralelo. En la consiguiente fase Reduce el motor recoge los resultados parciales y elabora un resultado global.

Mientras que el nodo maestro alberga por lo general los componentes namenode y jobtracker, en cada esclavo trabaja un datanode y un tasktracker. La siguiente imagen muestra una arquitectura Hadoop bÃ¡sica tal como funciona en la primera versiÃ³n del framework, dividida en una capa MapReduce y una capa HDFS.

